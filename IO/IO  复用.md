#  NIO



Standard IO是对字节流的读写，在进行IO之前，首先创建一个流对象，流对象进行读写操作都是按字节一个字节一个字节的来读或写。

而NIO把IO抽象成块，类似磁盘的读写，每次IO操作的单位都是一个块，块被读入内存之后就是一个byte[]，NIO一次可以读或写多个字节。


## 流与块

I/O 与 NIO 最重要的区别是数据打包和传输的方式，I/O 以流的方式处理数据，而 NIO 以块的方式处理数据
* 面向流的 I/O 一次处理一个字节数据: 一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。

面向块的 I/O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I/O 缺少一些面向流的 I/O 所具有的优雅性和简单性


## NIO 设计原理

NIO相对于BIO来说一大进步。客户端和服务器之间通过Channel通信。
* NIO可以在Channel进行读写操作。
* 这些Channel都会被注册在Selector多路复用器上。
* Selector通过一个线程不停的轮询这些Channel。找出已经准备就绪的Channel执行IO操作。
* NIO 通过一个线程轮询，实现千万个客户端的请求，这就是非阻塞NIO的特点


* 缓冲区Buffer：BIO是将数据直接写入或读取到Stream对象中。而NIO的数据操作都是在缓冲区中进行的,不会直接对通道进行读写数据，而是要先经过缓冲区。缓冲区实际上是一个数组。
  * Buffer最常见的类型是ByteBuffer，另外还有CharBuffer，ShortBuffer，IntBuffer，LongBuffer，FloatBuffer，DoubleBuffer。

* 通道Channel：和流不同，通道是双向的。NIO可以通过Channel进行数据的读，写和同时读写操作。通道分为两大类：一类是网络读写（SelectableChannel），一类是用于文件操作（FileChannel），我们使用的SocketChannel和ServerSocketChannel都是SelectableChannel的子类。
  *  流只能在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)
  *
* 多路复用器Selector：NIO编程的基础。多路复用器提供选择已经就绪的任务的能力。就是Selector会不断地轮询注册在其上的通道（Channel），如果某个通道处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以取得就绪的Channel集合，从而进行后续的IO操作。服务器端只要提供一个线程负责Selector的轮询，就可以接入成千上万个客户端，这就是JDK NIO库的巨大进步。

小结：NIO模型中通过SocketChannel和ServerSocketChannel完成套接字通道的实现。非阻塞/阻塞，同步，避免TCP建立连接使用三次握手带来的开销。


## 选择器
>  允许一个单独的线程同时监视多个通道，可以注册多个通道到同一个选择器上，然后使用一个单独的线程来“选择”已经就绪的通道。这种“选择”机制为一个单独线程管理多个通道提供了可能。

NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件

通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。 

因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件具有更好的性能。


## Reactor模型和Proactor模型

### 传统IO模型

<img width="489" alt="Screen Shot 2021-12-13 at 6 15 29 PM" src="https://user-images.githubusercontent.com/27160394/145793851-ddcf45d9-93a2-413f-9d85-c7fb094fb0d9.png">

* 每个客户端连接到达之后，服务端会分配一个线程给该客户端，该线程会处理包括读取数据，解码，业务计算，编码，以及发送数据整个过程；
* 同一时刻，服务端的吞吐量与服务器所提供的线程数量是呈线性关系的

存在的问题
* 服务器的并发量对服务端能够创建的线程数有很大的依赖关系，但是服务器线程却是不能无限增长的
* 服务端每个线程不仅要进行IO读写操作，而且还需要进行业务计算
* 服务端在获取客户端连接，读取数据，以及写入数据的过程都是阻塞类型的，在网络状况不好的情况下，这将极大的降低服务器每个线程的利用率，从而降低服务器吞吐量。

### Reactor事件驱动模型
> 以事件驱动来处理网络事件的，而Reactor是基于该API提出的一套IO模型

<img width="485" alt="Screen Shot 2021-12-13 at 6 17 43 PM" src="https://user-images.githubusercontent.com/27160394/145794215-326107a1-42d7-4df5-a973-5c868a8b0ac7.png">

将事件多路分解以及分配相应的事件服务进行处理，这个分派采用 server 集中处理（dispatch）

分解的事件以及对应的事件服务应用从分派服务中分离出去（handler）


主要有四个角色：
* 客户端连接
* Reactor: 将 I/O 事件分派给对应的 Handler
* Acceptor : Acceptor会不断地接收客户端的连接
* Handlers:  执行非阻塞读/写 任务


#### Reactor 单线程模型

Reactor单线程模型，指的是所有的I/O操作都在同一个NIO线程上面完成，NIO线程的职责如下：
* 作为NIO服务端，接收客户端的TCP连接；
* 作为NIO客户端，向服务端发起TCP连接；
* 读取通信对端的请求或者应答消息；
* 向通信对端发送消息请求或者应答消息；
* Reactor线程是个多面手，负责多路分离套接字，Accept新连接，并分派请求到处理器链中。
* 该模型 适用于处理器链中业务处理组件能快速完成的场景。不过，这种单线程模型不能充分利用多核资源，所以实际使用的不多。
* 对于一些小容量应用场景，可以使用单线程模型，但是对于高负载、大并发的应用却不合适，主要原因如下：
  * 一个NIO线程同时处理成百上千的链路，性能上无法支撑。即便NIO线程的CPU负荷达到100%，也无法满足海量消息的编码、解码、读取和发送；
  * 当NIO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往进行重发，这更加重了NIO线程的负载，最终导致大量消息积压和处理超时，NIO线程会成为系统的性能瓶颈；


#### 单 Reactor 多线程模型(业务处理与IO分离)

由于网络读写和业务操作都在同一个线程中，在高并发情况下，这里的系统瓶颈主要在两方面：
* 高频率的网络读写事件处理；
* 大量的业务操作处理；

* 使用一个线程进行客户端连接的接收以及网络读写事件的处理；
* 在接收到客户端连接之后，将该连接交由线程池进行数据的编解码以及业务计算。

Reactor多线程模型与单线程模型最大区别就是有一组NIO线程处理I/O操作，它的特点如下：
* 有一个专门的NIO线程-- acceptor新城用于监听服务端，接收客户端的TCP连接请求；
* 网络I/O操作--读、写等由一个NIO线程池负责，线程池可以采用标准的JDK线程池实现，它包含一个任务队列和N个可用的线程，
* 由这些NIO线程负责消息的读取、解码、编码和发送；1个NIO线程可以同时处理N条链路，但是1个链路只对应1个NIO线程，防止发生并发操作问题。
* 在绝大多数场景下，Reactor多线程模型都可以满足性能需求；但是，在极特殊应用场景中，一个NIO线程负责监听和处理所有的客户端
* 连接可能会存在性能问题。例如百万客户端并发连接，或者服务端需要对客户端的握手信息进行安全认证，认证本身非常损耗性能。
* 这类场景下，单独一个Acceptor线程可能会存在性能不足问题，为了解决性能问题，产生了第三种Reactor线程模型--主从Reactor多线程模型


#### 主从 Reactor 多线程模型

改进后的Reactor模型将Reactor拆分为了mainReactor和subReactor
* mainReactor主要进行客户端连接的处理，处理完成之后将该连接交由subReactor以处理客户端的网络读写
* subReactor则是使用一个线程池来支撑的，其读写能力将会随着线程数的增多而大大增加

特点是：服务端用于接收客户端连接的不再是1个单独的NIO线程，而是一个独立的NIO线程池。
* Acceptor接收到客户端TCP连接请求处理完成后（可能包含接入认证等），将新创建的SocketChannel注册到I/O线程池（sub reactor线程池）的某个I/O线程上，由它负责SocketChannel
的读写和编解码工作。
* Acceptor线程池只用于客户端的登录、握手和安全认证，一旦链路建立成功，就将链路注册到后端subReactor线程池的I/O线程上，
* 有I/O线程负责后续的I/O操作。第三种模型比起第二种模型，是将Reactor分成两部分，mainReactor负责监听server socket，accept新连接，
* 并将建立的socket分派给subReactor。subReactor负责多路分离已连接的socket，读写网 络数据，对业务处理功能，其扔给worker线程池完成。
* 通常，subReactor个数上可与CPU个数等同。




## I/O 复用
目前流程的多路复用IO实现主要包括四种: select、poll、epoll、kqueue

| IO模型	| 相对性能 | 关键思路| 操作系统| JAVA支持情况|
|--------|--------|-------|---------|-----------|
|select|较高|Reactor|windows/Linux|支持,Reactor模式(反应器设计模式)。Linux操作系统的 kernels 2.4内核版本之前，默认使用select；而目前windows下对同步IO的支持，都是select模型|
|poll|较高|Reactor|Linux|Linux下的JAVA NIO框架，Linux kernels 2.6内核版本之前使用poll进行支持。也是使用的Reactor模式|
|epoll|高|Reactor/Proactor|Linux|由于Linux下没有Windows下的IOCP技术提供真正的 异步IO 支持，所以Linux下使用epoll模拟异步IO|
|kqueue|高|Proactor|Linux|目前JAVA的版本不支持|



1. select==> 时间复杂度 O(n)
* 它仅仅知道了，有 I/O 事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以 select 具有 O(n)的无差别轮询复杂度，同时处理的流越多，无差别轮询时间就越长。

2. poll==> 时间复杂度 O(n)
* poll 本质上和 select 没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个 fd 对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的.

3. epoll==> 时间复杂度 O(1)
* epoll 可以理解为 event poll，不同于忙轮询和无差别轮询，epoll 会把哪个流发生了怎样的 I/O 事件通知我们。所以我们说 epoll 实际上是事件驱动（每个事件关联上 fd）的，此时我们对这些流的操作都是有意义的。（复杂度降低到了 O(1)）

select，poll，epoll 都是 IO 多路复用的机制。I/O 多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪 （一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。
* select，poll，epoll 本质上都是同步 I/O，因为他们都 需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，
* 异步 I/O 则无需自己负责进行读写，异步 I/O 的实现 会负责把数据从内核拷贝到用户空间。


## Netty

Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序
